# Values pour kube-prometheus-stack
# Documentation: https://github.com/prometheus-community/helm-charts/tree/main/charts/kube-prometheus-stack

# Prometheus configuration
prometheus:
  prometheusSpec:
    # Rétention des données
    retention: 30d
    retentionSize: "20GB"
    
    # Resources
    resources:
      requests:
        cpu: 200m
        memory: 512Mi
      limits:
        cpu: 1000m
        memory: 2Gi
    
    # Storage persistant (optionnel, à activer si besoin)
    storageSpec:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 20Gi
    
    # Service Monitors - découverte automatique
    serviceMonitorSelectorNilUsesHelmValues: false
    podMonitorSelectorNilUsesHelmValues: false
    ruleSelectorNilUsesHelmValues: false
    
    # Scrape tous les namespaces
    serviceMonitorNamespaceSelector: {}
    podMonitorNamespaceSelector: {}

  # Service type
  service:
    type: ClusterIP  # Pas besoin de LoadBalancer, on accède via Grafana

# Grafana configuration
grafana:
  # Admin credentials
  adminPassword: admin  # À CHANGER en production avec un secret
  
  # Service type - Exposé via MetalLB
  service:
    type: LoadBalancer
    annotations:
      metallb.universe.tf/loadBalancerIPs: "192.168.1.83"
  
  # Persistence
  persistence:
    enabled: true
    size: 10Gi
  
  # Resources
  resources:
    requests:
      cpu: 100m
      memory: 128Mi
    limits:
      cpu: 500m
      memory: 512Mi
  
  # Configuration des datasources
  datasources:
    datasources.yaml:
      apiVersion: 1
      datasources:
        - name: Prometheus
          type: prometheus
          url: http://kube-prometheus-stack-prometheus.monitoring.svc:9090
          access: proxy
          isDefault: true
          jsonData:
            timeInterval: 30s
  
  # Dashboards par défaut
  defaultDashboardsEnabled: true
  defaultDashboardsTimezone: Europe/Paris
  
  # Import de dashboards personnalisés
  dashboardProviders:
    dashboardproviders.yaml:
      apiVersion: 1
      providers:
        - name: 'default'
          orgId: 1
          folder: ''
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/default
        - name: 'kubernetes'
          orgId: 1
          folder: 'Kubernetes'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/kubernetes
        - name: 'applications'
          orgId: 1
          folder: 'Applications'
          type: file
          disableDeletion: false
          editable: true
          options:
            path: /var/lib/grafana/dashboards/applications
  
  # Dashboards importés automatiquement
  dashboards:
    kubernetes:
      # Dashboard Cluster Overview
      k8s-cluster:
        gnetId: 7249
        revision: 1
        datasource: Prometheus
      # Dashboard Node Exporter
      node-exporter:
        gnetId: 1860
        revision: 31
        datasource: Prometheus
      # Dashboard Pods
      k8s-pods:
        gnetId: 6417
        revision: 1
        datasource: Prometheus
    applications:
      # Dashboard ArgoCD
      argocd:
        gnetId: 14584
        revision: 1
        datasource: Prometheus

# AlertManager configuration
alertmanager:
  alertmanagerSpec:
    # Resources
    resources:
      requests:
        cpu: 50m
        memory: 64Mi
      limits:
        cpu: 200m
        memory: 128Mi
    
    # Storage
    storage:
      volumeClaimTemplate:
        spec:
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 5Gi
  
  # Configuration des routes d'alerte
  config:
    global:
      resolve_timeout: 5m
    
    route:
      group_by: ['alertname', 'cluster', 'service']
      group_wait: 10s
      group_interval: 10s
      repeat_interval: 12h
      receiver: 'null'
      routes:
        - match:
            alertname: Watchdog
          receiver: 'null'
        - match:
            severity: critical
          receiver: 'null'  # À configurer plus tard avec email/Slack
    
    receivers:
      - name: 'null'

# Node Exporter - Métriques des nœuds
prometheus-node-exporter:
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# Kube State Metrics - Métriques des objets K8s
kube-state-metrics:
  resources:
    requests:
      cpu: 50m
      memory: 64Mi
    limits:
      cpu: 200m
      memory: 128Mi

# Désactiver certains composants non nécessaires pour le moment
kubeEtcd:
  enabled: false  # K3s utilise SQLite par défaut

kubeControllerManager:
  enabled: false  # Pas accessible sur K3s

kubeScheduler:
  enabled: false  # Pas accessible sur K3s

# Règles d'alertes par défaut
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: false
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: false
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true
